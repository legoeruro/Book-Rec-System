{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code for the Cosine Similarity recommendation system. The limitations of this is:\n",
    "1. Only take book data into account, and doesn't compare user-to-user\n",
    "2. The amount of memory and computing power is large, with the whole book dataset python needs to allocate ~80Gb. Currently to get around this I'm using 20000 instances of book data.\n",
    "\n",
    "*Tunable parameters:\n",
    "- Number of training instances\n",
    "- m: maximum number of books to consider for recommendations (take m books with highest rating from user and consider them for similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/legoeuro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from brs_data_preprocessing import get_preprocessed_data as preproc, merged_book_ratings as merge\n",
    "\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersDf, bookDf, ratingDf = preproc('input/Users.csv', 'input/Books.csv', 'input/Ratings.csv')\n",
    "\n",
    "#Data concatenation\n",
    "bookInfo = []\n",
    "for _, row in bookDf.iterrows():\n",
    "    bookInfo.append(f\"{row['Book-Title']} {row['Book-Author']} {row['Publisher']}\")\n",
    "bookDf[\"info\"] = bookInfo\n",
    "\n",
    "#configs\n",
    "bookDf = bookDf.iloc[:20000]\n",
    "ratingDf['ISBN'] = ratingDf['ISBN'].astype(str)\n",
    "bookDf['ISBN'] = bookDf[\"ISBN\"].astype(str)\n",
    "bookDf['id'] = bookDf.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add index for later steps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess and clean book information\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>info</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>classical mythology mark p. o. morford oxford ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>clara callan richard bruce wright harperflamin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>decision normandy carlo d'este harperperennial</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>flu: story great influenza pandemic 1918 searc...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>mummies urumchi e. j. w. barber w. w. norton &amp;...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN  ... id\n",
       "0  0195153448  ...  0\n",
       "1  0002005018  ...  1\n",
       "2  0060973129  ...  2\n",
       "3  0374157065  ...  3\n",
       "4  0393045218  ...  4\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#from https://www.kaggle.com/code/muhammadayman/recommendation-system-using-cosine-similarity#Feature-Engineering\n",
    "stop = stopwords.words('english')\n",
    "def preprocess(column):\n",
    "    #make all words with lower letters\n",
    "    column = column.str.lower()\n",
    "    #getting rid of any punctution\n",
    "    column = column.str.replace('http\\S+|www.\\S+|@|%|:|,|', '', case=False)\n",
    "    #spliting each sentence to words to apply previous funtions on them \n",
    "    word_tokens = column.str.split()\n",
    "    keywords = word_tokens.apply(lambda x: [item for item in x if item not in stop])\n",
    "    #assemble words of each sentence again and assign them in new column\n",
    "    for i in range(len(keywords)):\n",
    "        keywords[i] = \" \".join(keywords[i])\n",
    "        column = keywords\n",
    "\n",
    "    return column\n",
    "bookDf['info'] = preprocess(bookDf['info'])\n",
    "# bookDf['Book-Title'] = preprocess(bookDf['Book-Title'])\n",
    "bookDf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# mms = preprocessing.MinMaxScaler()\n",
    "\n",
    "# bookDf['Year-Of-Publication'] = (bookDf['Year-Of-Publication'] - bookDf['Year-Of-Publication'].mean()) / bookDf['Year-Of-Publication'].std() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply cosine vectorizer to all books; Find user top 10 books that they have not read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|        |       ISBN | Book-Title                                       | Book-Author       |   Year-Of-Publication | Publisher   | info                                                                      |    id |   User-ID |   Book-Rating |\n",
      "|-------:|-----------:|:-------------------------------------------------|:------------------|----------------------:|:------------|:--------------------------------------------------------------------------|------:|----------:|--------------:|\n",
      "| 344029 | 0515107662 | The Sherbrooke Bride (Bride Trilogy (Paperback)) | Catherine Coulter |                  1996 | Jove Books  | sherbrooke bride (bride trilogy (paperback)) catherine coulter jove books | 15978 |    276709 |            10 |\n",
      "[('The Scottish Bride (Bride Trilogy (Paperback))', 0.9090909090909093), ('The Heiress Bride (Bride Trilogy (Paperback))', 0.9090909090909093), ('The Sherbrooke Twins', 0.6154574548966638), ('The Cove', 0.5393598899705937), ('The Maze', 0.5393598899705937), ('The Edge', 0.5393598899705937), ('The Target', 0.5393598899705937), ('Pendragon', 0.5393598899705937), ('Rosehaven', 0.5393598899705937), ('Riptide', 0.5393598899705937)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "CV = CountVectorizer()\n",
    "titleVect = CV.fit_transform(bookDf['info'])\n",
    "# authVect = CV.fit_transform(bookDf['Book-Author'])\n",
    "# pubVect = CV.fit_transform(bookDf['Publisher'])\n",
    "\n",
    "titleSim = cosine_similarity(titleVect)\n",
    "\n",
    "normalize = 10\n",
    "bookRatingMerge = merge(ratings_df=ratingDf, books_df=bookDf)\n",
    "def recommendFromUser(userId, n, m):\n",
    "    \"\"\"\n",
    "    userId: id of the user in the dataset\n",
    "    n: number of recommendations\n",
    "    m: maximum number of books to consider for recommendations (take m books with highest rating from user and consider them for similarity)\n",
    "       made with the assumption that book-rating only goes from 1 to 10\n",
    "    \"\"\"\n",
    "    userRatings = bookRatingMerge[bookRatingMerge['User-ID'] == userId]\n",
    "    userRatings = userRatings[userRatings['Book-Rating'] > 5]\n",
    "\n",
    "    ratingTruncated = userRatings.nlargest(m, 'Book-Rating')\n",
    "    print(ratingTruncated.to_markdown())\n",
    "    recommendations = []\n",
    "    for _, row in bookDf.iterrows():\n",
    "        bookId = row['ISBN']\n",
    "        bookIndex = bookDf[bookDf['ISBN'] == bookId].index[0]\n",
    "        sim = 0\n",
    "        isBookRead = False\n",
    "        for _, ratingRow in ratingTruncated.iterrows():\n",
    "            ratingBookId = ratingRow['ISBN']\n",
    "            ratingBookIndex = bookDf[bookDf['ISBN'] == ratingBookId].index[0]\n",
    "            if bookIndex == ratingBookIndex:\n",
    "                isBookRead = True\n",
    "                break\n",
    "            #weight by rating\n",
    "            sim += ratingRow['Book-Rating']/(normalize) * titleSim[bookIndex][ratingBookIndex]\n",
    "        if (not isBookRead):\n",
    "            recommendations.append((bookId, sim)) \n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    return recommendations[:n]\n",
    "\n",
    "#Example: get the top recommendation for the user with id 276709\n",
    "recommendation = recommendFromUser(276709, 10, 10)\n",
    "mappedRec = map(lambda x: (bookDf[bookDf['ISBN'] == x[0]]['Book-Title'].values[0], x[1]), recommendation)\n",
    "print(list(mappedRec))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
